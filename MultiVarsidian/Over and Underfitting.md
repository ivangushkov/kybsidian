## Over and Underfitting

**Overfitting** - fitting a model which follows the errors realizations instead of the trend in the data. Overfitting is associated to having a complex model with lots of features which will yield a great performance on the training set and no generalizable model. Also, since we follow the error realizations, the model will vary a not with different errors realizations, meaning we get higher variance in the parameters. [[bias variance tradeoff]] tradeoff.

**Underfitting** - fitting a model which follows a general trend on the "macro" scale, but does not reflect some important features in the "micro" scale. Will depend less on specific error realization, thus reduced variance. Will for sure though get high bias, both on training and unseen data.

#### Geometrical Interpretation

#### Practical Examples
